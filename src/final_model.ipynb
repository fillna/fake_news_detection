{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from transformers import (BertForSequenceClassification, BertTokenizer,\n",
    "                          RobertaForSequenceClassification, RobertaTokenizer,\n",
    "                          XLNetForSequenceClassification, XLNetTokenizer,\n",
    "                          AlbertForSequenceClassification, AlbertTokenizer,\n",
    "                          AdamW, get_linear_schedule_with_warmup\n",
    "                          )\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [lemmatizer.lemmatize(stemmer.stem(word)) for word in words if word not in stop_words]\n",
    "\n",
    "    return ' '.join(words)\n",
    "\n",
    "def encode_label(label:str):\n",
    "    if label == 'true': return 0\n",
    "    if label == 'mostly-true': return 1\n",
    "    if label == 'barely-true': return 2\n",
    "    if label == 'half-true': return 3\n",
    "    if label == 'false': return 4\n",
    "    if label == 'pants-fire': return 5\n",
    "    return -1\n",
    "\n",
    "def tokenize(X, y):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for txt in X.tolist():\n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "                            txt,\n",
    "                            add_special_tokens = True,\n",
    "                            max_length = 100,\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,\n",
    "                            return_tensors = 'pt'\n",
    "                    )\n",
    "        input_ids.append(encoded_text['input_ids'])\n",
    "        attention_masks.append(encoded_text['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(torch.from_numpy(y.to_numpy()))\n",
    "    \n",
    "    return input_ids, attention_masks, labels\n",
    "\n",
    "def accuracy(pred, actual):\n",
    "    pred_flat = np.argmax(pred, axis=1).flatten()\n",
    "    labels_flat = actual.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>context</th>\n",
       "      <th>target</th>\n",
       "      <th>speaker</th>\n",
       "      <th>documented_time</th>\n",
       "      <th>author_score</th>\n",
       "      <th>headline</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "      <th>src_label</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>stated on October 28, 2023 in a screenshot sha...</td>\n",
       "      <td>4</td>\n",
       "      <td>Madison Czopek</td>\n",
       "      <td>October 31, 2023</td>\n",
       "      <td>[  5   3  16  54 473 152]</td>\n",
       "      <td>haaretz investig reveal discrep israel report ...</td>\n",
       "      <td>viral oct social medium post claim israel lie ...</td>\n",
       "      <td>haaretz isra newspap said x claim report blata...</td>\n",
       "      <td>4</td>\n",
       "      <td>81_gaza_palestinian_israelpalestin_israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>stated on May 30, 2023 in Interview:</td>\n",
       "      <td>2</td>\n",
       "      <td>Laura Schulte</td>\n",
       "      <td>October 31, 2023</td>\n",
       "      <td>[26 45 39 41 44 11]</td>\n",
       "      <td>wisconsin histor think larg continu blue state</td>\n",
       "      <td>wisconsin help swing presidenti vote donald tr...</td>\n",
       "      <td>although wisconsin vote democrat presidenti ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>3_wisconsin_governor_walker_republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>stated on October 27, 2023 in a post:</td>\n",
       "      <td>4</td>\n",
       "      <td>Ciara O'Rourke</td>\n",
       "      <td>October 30, 2023</td>\n",
       "      <td>[  5   3  16  54 473 152]</td>\n",
       "      <td>airport salzburg austria counter peopl flew au...</td>\n",
       "      <td>social medium post poi encourag peopl unfortun...</td>\n",
       "      <td>social medium post poi encourag peopl unfortun...</td>\n",
       "      <td>4</td>\n",
       "      <td>-1_barack_obama_clinton_democrat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source                                            context  target  \\\n",
       "0  Instagram posts  stated on October 28, 2023 in a screenshot sha...       4   \n",
       "1     Scott Walker               stated on May 30, 2023 in Interview:       2   \n",
       "2  Instagram posts              stated on October 27, 2023 in a post:       4   \n",
       "\n",
       "          speaker    documented_time               author_score  \\\n",
       "0  Madison Czopek   October 31, 2023  [  5   3  16  54 473 152]   \n",
       "1   Laura Schulte   October 31, 2023        [26 45 39 41 44 11]   \n",
       "2  Ciara O'Rourke   October 30, 2023  [  5   3  16  54 473 152]   \n",
       "\n",
       "                                            headline  \\\n",
       "0  haaretz investig reveal discrep israel report ...   \n",
       "1     wisconsin histor think larg continu blue state   \n",
       "2  airport salzburg austria counter peopl flew au...   \n",
       "\n",
       "                                             article  \\\n",
       "0  viral oct social medium post claim israel lie ...   \n",
       "1  wisconsin help swing presidenti vote donald tr...   \n",
       "2  social medium post poi encourag peopl unfortun...   \n",
       "\n",
       "                                             summary  src_label  \\\n",
       "0  haaretz isra newspap said x claim report blata...          4   \n",
       "1  although wisconsin vote democrat presidenti ca...          1   \n",
       "2  social medium post poi encourag peopl unfortun...          4   \n",
       "\n",
       "                                       topic  \n",
       "0  81_gaza_palestinian_israelpalestin_israel  \n",
       "1     3_wisconsin_governor_walker_republican  \n",
       "2           -1_barack_obama_clinton_democrat  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/enriched_politifact.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df, df['src_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_base_train, X_base_test = X_train['headline'], X_test['headline']\n",
    "X_topic_train, X_topic_test = X_train['headline'] + ' ' + X_train['topic'], X_test['headline'] + ' ' + X_test['topic']\n",
    "X_sumamry_train,  X_sumamry_test = X_train['headline'] + ' ' + X_train['summary'], X_test['headline'] + ' ' + X_test['summary']\n",
    "X_full_train,  X_full_test= X_train['headline'] + ' ' + X_train['topic'] + ' ' + X_train['summary'] + X_train['source'], X_test['headline'] + ' ' + X_test['topic'] + ' ' + X_test['summary'] + X_test['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'due war iraq american dead sever wound suffer serious health problem relat post traumat stress syndrom'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_base_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "train_input_ids, train_attention_masks, train_labels = tokenize(X_base_train, y_train)\n",
    "valid_input_ids, valid_attention_masks, valid_labels = tokenize(X_base_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "valid_dataset = TensorDataset(valid_input_ids, valid_attention_masks, valid_labels)\n",
    "\n",
    "epochs = 3\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size)\n",
    "valid_dataloader = DataLoader(\n",
    "            valid_dataset,\n",
    "            sampler = SequentialSampler(valid_dataset),\n",
    "            batch_size = batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'sequence_summary.summary.bias', 'logits_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = XLNetForSequenceClassification.from_pretrained(\n",
    "    \"xlnet-base-cased\",\n",
    "    num_labels = 6, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False)\n",
    "\n",
    "desc = model.cuda()\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = len(train_dataloader) * epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 3 ========\n",
      "Batch 100 of 2346.\n",
      "Batch 200 of 2346.\n",
      "Batch 300 of 2346.\n",
      "Batch 400 of 2346.\n",
      "Batch 500 of 2346.\n",
      "Batch 600 of 2346.\n",
      "Batch 700 of 2346.\n",
      "Batch 800 of 2346.\n",
      "Batch 900 of 2346.\n",
      "Batch 1000 of 2346.\n",
      "Batch 1100 of 2346.\n",
      "Batch 1200 of 2346.\n",
      "Batch 1300 of 2346.\n",
      "Batch 1400 of 2346.\n",
      "Batch 1500 of 2346.\n",
      "Batch 1600 of 2346.\n",
      "Batch 1700 of 2346.\n",
      "Batch 1800 of 2346.\n",
      "Batch 1900 of 2346.\n",
      "Batch 2000 of 2346.\n",
      "Batch 2100 of 2346.\n",
      "Batch 2200 of 2346.\n",
      "Batch 2300 of 2346.\n",
      "Avg. Train Loss: 1.57\n",
      "=====Validating====\n",
      "Avg. Val Acc: 0.41\n",
      "Val Loss: 1.51\n",
      "======== Epoch 2 / 3 ========\n",
      "Batch 100 of 2346.\n",
      "Batch 200 of 2346.\n",
      "Batch 300 of 2346.\n",
      "Batch 400 of 2346.\n",
      "Batch 500 of 2346.\n",
      "Batch 600 of 2346.\n",
      "Batch 700 of 2346.\n",
      "Batch 800 of 2346.\n",
      "Batch 900 of 2346.\n",
      "Batch 1000 of 2346.\n",
      "Batch 1100 of 2346.\n",
      "Batch 1200 of 2346.\n",
      "Batch 1300 of 2346.\n",
      "Batch 1400 of 2346.\n",
      "Batch 1500 of 2346.\n",
      "Batch 1600 of 2346.\n",
      "Batch 1700 of 2346.\n",
      "Batch 1800 of 2346.\n",
      "Batch 1900 of 2346.\n",
      "Batch 2000 of 2346.\n",
      "Batch 2100 of 2346.\n",
      "Batch 2200 of 2346.\n",
      "Batch 2300 of 2346.\n",
      "Avg. Train Loss: 1.45\n",
      "=====Validating====\n",
      "Avg. Val Acc: 0.42\n",
      "Val Loss: 1.46\n",
      "======== Epoch 3 / 3 ========\n",
      "Batch 100 of 2346.\n",
      "Batch 200 of 2346.\n",
      "Batch 300 of 2346.\n",
      "Batch 400 of 2346.\n",
      "Batch 500 of 2346.\n",
      "Batch 600 of 2346.\n",
      "Batch 700 of 2346.\n",
      "Batch 800 of 2346.\n",
      "Batch 900 of 2346.\n",
      "Batch 1000 of 2346.\n",
      "Batch 1100 of 2346.\n",
      "Batch 1200 of 2346.\n",
      "Batch 1300 of 2346.\n",
      "Batch 1400 of 2346.\n",
      "Batch 1500 of 2346.\n",
      "Batch 1600 of 2346.\n",
      "Batch 1700 of 2346.\n",
      "Batch 1800 of 2346.\n",
      "Batch 1900 of 2346.\n",
      "Batch 2000 of 2346.\n",
      "Batch 2100 of 2346.\n",
      "Batch 2200 of 2346.\n",
      "Batch 2300 of 2346.\n",
      "Avg. Train Loss: 1.36\n",
      "=====Validating====\n",
      "Avg. Val Acc: 0.42\n",
      "Val Loss: 1.51\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed_val = 30\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            print('Batch {} of {}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_ids, b_mask, b_labels = batch\n",
    "\n",
    "        model.zero_grad()        \n",
    "        loss, logits = model(b_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_mask, \n",
    "                             labels=b_labels,\n",
    "                             return_dict=False)\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader) \n",
    "               \n",
    "    print(\"Avg. Train Loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"=====Validating====\")\n",
    "\n",
    "    model.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_ids, b_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            (loss, logits, _) = model(b_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_mask,\n",
    "                                   labels=b_labels,\n",
    "                                   return_dict=False)\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        total_eval_accuracy += accuracy(logits, label_ids)\n",
    "        \n",
    "    avg_val_accuracy = total_eval_accuracy / len(valid_dataloader)\n",
    "    print(\"Avg. Val Acc: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(valid_dataloader)\n",
    "    print(\"Val Loss: {0:.2f}\".format(avg_val_loss))\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.952578\n",
      "Testing Accuracy: 0.946250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     12823\n",
      "           1       0.95      0.95      0.95     12777\n",
      "\n",
      "    accuracy                           0.95     25600\n",
      "   macro avg       0.95      0.95      0.95     25600\n",
      "weighted avg       0.95      0.95      0.95     25600\n",
      "\n",
      "Training Accuracy: 0.977538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       373\n",
      "           0       0.98      1.00      0.99     20063\n",
      "           1       0.00      0.00      0.00        88\n",
      "\n",
      "    accuracy                           0.98     20524\n",
      "   macro avg       0.33      0.33      0.33     20524\n",
      "weighted avg       0.96      0.98      0.97     20524\n",
      "\n",
      "Training Accuracy: 0.590431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false       0.00      0.00      0.00      8406\n",
      "        true       0.59      1.00      0.74     12118\n",
      "\n",
      "    accuracy                           0.59     20524\n",
      "   macro avg       0.30      0.50      0.37     20524\n",
      "weighted avg       0.35      0.59      0.44     20524\n",
      "\n",
      "Training Accuracy: 0.546531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.18      0.28      2287\n",
      "           1       0.45      0.68      0.54      4352\n",
      "           2       0.51      0.34      0.41      3186\n",
      "           3       0.62      0.18      0.28      2382\n",
      "           4       0.60      0.83      0.70      7049\n",
      "           5       0.77      0.34      0.47      1268\n",
      "\n",
      "    accuracy                           0.55     20524\n",
      "   macro avg       0.59      0.43      0.45     20524\n",
      "weighted avg       0.57      0.55      0.51     20524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from clickbait import ClickbaitModel\n",
    "from sentiment_log import SentimentModel\n",
    "from spam import SpamModel\n",
    "from source_reliable import SourceReliableModel\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['headline'], df['target'], test_size=.2, random_state=11)\n",
    "\n",
    "clickM = ClickbaitModel()\n",
    "sentiM = SentimentModel()\n",
    "spamM = SpamModel()\n",
    "srcM = SourceReliableModel()\n",
    "\n",
    "sentiM.fit(X_train)\n",
    "spamM.fit(X_train)\n",
    "srcM.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lst = [0.946, 0.976, 0.412, 0.589]\n",
    "weight = [acc/sum(acc_lst) for acc in acc_lst]\n",
    "clickbaitV = clickM.predict(X_test)[1] * weight[0]\n",
    "sentiV = sentiM.predict(X_test)[1] * weight[1]\n",
    "spamV = spamM.predict(X_test)[1] * weight[2]\n",
    "sourceV = srcM.predict(X_test)[1] * weight[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clickbaitV = clickM.predict(X_train)[1] * weight[0]\n",
    "train_sentiV = sentiM.predict(X_train)[1] * weight[1]\n",
    "train_spamV = spamM.predict(X_train)[1] * weight[2]\n",
    "train_sourceV = srcM.predict(X_train)[1] * weight[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "veracity_train = pd.DataFrame({'clickbait':train_clickbaitV, 'sentiment': train_sentiV, 'spam': train_spamV, 'source': train_sourceV})\n",
    "veracity_test = pd.DataFrame({'clickbait':clickbaitV, 'sentiment': sentiV, 'spam': spamV, 'source': sourceV})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3047138047138047"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='liblinear')\n",
    "clf.fit(veracity_train, y_train)\n",
    "clf.score(veracity_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
