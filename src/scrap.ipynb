{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call `scrape_website` to retrieve a page of article headline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "dates = []\n",
    "statements = []\n",
    "sources = []\n",
    "targets = []\n",
    "urls = []\n",
    "source_urls = []\n",
    "\n",
    "def scrape_website(page_number:int):\n",
    "    ''' Scrape and store the authors, statements, sources, targets, urls, \n",
    "    and source urls of a page of articles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    page_number: int\n",
    "        Page number.\n",
    "    '''\n",
    "\n",
    "    domain = 'https://www.politifact.com'\n",
    "    page_num = str(page_number)\n",
    "    URL = 'https://www.politifact.com/factchecks/list/?page=' + page_num\n",
    "    webpage = requests.get(URL)\n",
    "    soup = BeautifulSoup(webpage.text, 'html.parser')\n",
    "\n",
    "    statement_footer = soup.find_all('footer', attrs={'class':'m-statement__footer'}) # Author and date\n",
    "    statement_quote = soup.find_all('div', attrs={'class':'m-statement__quote'}) # Statement\n",
    "    statement_meta = soup.find_all('div', attrs={'class':'m-statement__meta'}) # Source\n",
    "    target = soup.find_all('div', attrs={'class':'m-statement__meter'}) # Target\n",
    "\n",
    "    for i in statement_footer:\n",
    "        link1 = i.text.strip()\n",
    "        name_and_date = link1.split()\n",
    "        first_name = name_and_date[1]\n",
    "        last_name = name_and_date[2]\n",
    "        full_name = first_name + ' '+ last_name\n",
    "        sep_index = name_and_date.index('•')\n",
    "        month = name_and_date[sep_index+1]\n",
    "        day = name_and_date[sep_index+2]\n",
    "        year = name_and_date[sep_index+3]\n",
    "        date = month + ' ' + day + ' ' + year \n",
    "\n",
    "        authors.append(full_name)\n",
    "        dates.append(date)\n",
    "\n",
    "    for i in statement_quote:\n",
    "        link2 = i.find_all('a')\n",
    "        statement_text = link2[0].text.strip()\n",
    "        statements.append(statement_text)\n",
    "        urls.append(domain + link2[0].get('href'))\n",
    "\n",
    "    for i in statement_meta:\n",
    "        link3 = i.find_all('a')\n",
    "        source_text = link3[0].text.strip()\n",
    "        sources.append(source_text)\n",
    "        source_urls.append(domain + link3[0].get('href'))\n",
    "\n",
    "    for i in target:\n",
    "        link4 = i.find('div', attrs = {'class':'c-image'}).find('img').get('alt')\n",
    "        targets.append(link4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call `scrape_article` to retrieve full data related to the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'https://www.politifact.com'\n",
    "highlights = []\n",
    "articles = []\n",
    "references = []\n",
    "categories = []\n",
    "category_urls = []\n",
    "\n",
    "def scrape_article(URL:str):\n",
    "    ''' Scrape and store revelant information of an article, including original\n",
    "    text, highlights, list of references, list of categories, list of category urls.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    URL: str\n",
    "        URL of an article.\n",
    "    '''\n",
    "    webpage = requests.get(URL, timeout=120)\n",
    "    soup = BeautifulSoup(webpage.text, 'html.parser')\n",
    "\n",
    "    tldr = soup.find_all('div', attrs={'class':'short-on-time'})\n",
    "    if(len(tldr) > 0):\n",
    "        highlights.append(tldr[0].text.strip())\n",
    "    else: highlights.append(None)\n",
    "\n",
    "    paragraphs = soup.find('article', attrs={'class':'m-textblock'}).find_all('p')\n",
    "    article = \" \".join([p.text.strip() for p in paragraphs])\n",
    "    articles.append(article)\n",
    "\n",
    "    refs = soup.find('article', attrs={'class':'m-superbox__content'}).find_all('p')\n",
    "    reference = [r.text.strip()[:r.text.index(',')] for r in refs if ',' in r.text]\n",
    "    references.append(reference)\n",
    "\n",
    "    cats = soup.find_all('li', attrs={'class': 'm-list__item'})\n",
    "    category = [cat.text.strip() for cat in cats]\n",
    "    url = [domain + cat.find('a').get('href') for cat in cats]\n",
    "    categories.append(category)\n",
    "    category_urls.append(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call `scrape_source_score` to retrieve score card of the article source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_true = []\n",
    "src_mostly_true = []\n",
    "src_half_true = []\n",
    "src_mostly_false = []\n",
    "src_false = []\n",
    "src_pants_on_fire = []\n",
    "\n",
    "def scrape_source_score(URL:str):\n",
    "    ''' Scrape and store revelant scores of a source.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    URL: str\n",
    "        URL of a source.\n",
    "    '''\n",
    "    webpage = requests.get(URL, timeout=120)\n",
    "    soup = BeautifulSoup(webpage.text, 'html.parser')\n",
    "\n",
    "    scorecard = soup.find_all('p', attrs={'class':'m-scorecard__checks'})\n",
    "    true, mtrue, htrue, mfalse, false, pof = [int(re.findall(pattern='[0-9]+', string=s.text.strip())[0]) for s in scorecard]\n",
    "    src_true.append(true)\n",
    "    src_mostly_true.append(mtrue)\n",
    "    src_half_true.append(htrue)\n",
    "    src_mostly_false.append(mfalse)\n",
    "    src_false.append(false)\n",
    "    src_pants_on_fire.append(pof)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>headline</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>highlight</th>\n",
       "      <th>article</th>\n",
       "      <th>references</th>\n",
       "      <th>categories</th>\n",
       "      <th>category_urls</th>\n",
       "      <th>src_true</th>\n",
       "      <th>src_mostly_true</th>\n",
       "      <th>src_half_true</th>\n",
       "      <th>src_mostly_false</th>\n",
       "      <th>src_false</th>\n",
       "      <th>src_pants_on_fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ciara O'Rourke</td>\n",
       "      <td>“The airport in Salzburg, Austria, has a count...</td>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>October 30, 2023</td>\n",
       "      <td>false</td>\n",
       "      <td>This rumor stems from an ad. No such counter e...</td>\n",
       "      <td>A social media post poised to encourage people...</td>\n",
       "      <td>instagram_post,the_local,washington_post,x_post</td>\n",
       "      <td>transportation,facebook_fact_checks,instagram_...</td>\n",
       "      <td>['https://www.politifact.com/transportation/',...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>480</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ciara O'Rourke</td>\n",
       "      <td>Video shows Palestinians pretending to be corp...</td>\n",
       "      <td>Viral image</td>\n",
       "      <td>October 30, 2023</td>\n",
       "      <td>false</td>\n",
       "      <td>This video is 10 years old and shows student p...</td>\n",
       "      <td>The Gaza Health Ministry has said the Palestin...</td>\n",
       "      <td>instagram_post,instagram_post,youtube</td>\n",
       "      <td>israel,facebook_fact_checks,viral_image</td>\n",
       "      <td>['https://www.politifact.com/israel/', 'https:...</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "      <td>764</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loreben Tuquero</td>\n",
       "      <td>The life span of a wind tower generator lasts ...</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>October 30, 2023</td>\n",
       "      <td>false</td>\n",
       "      <td>A study by energy industry experts showed that...</td>\n",
       "      <td>Let’s clear the air. Do wind turbine component...</td>\n",
       "      <td>none,x_post,facebook_post,interview,interview,...</td>\n",
       "      <td>climate_change,energy,facebook_fact_checks,fac...</td>\n",
       "      <td>['https://www.politifact.com/climate-change/',...</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>108</td>\n",
       "      <td>247</td>\n",
       "      <td>1532</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ciara O'Rourke</td>\n",
       "      <td>Matthew Perry died because of a COVID-19 vaccine.</td>\n",
       "      <td>Instagram posts</td>\n",
       "      <td>October 30, 2023</td>\n",
       "      <td>false</td>\n",
       "      <td>Actor Matthew Perry died Oct. 28, but his caus...</td>\n",
       "      <td>Actor Matthew Perry died Oct. 28, setting off ...</td>\n",
       "      <td>instagram_post,instagram_post,instagram_post,i...</td>\n",
       "      <td>facebook_fact_checks,coronavirus,instagram_posts</td>\n",
       "      <td>['https://www.politifact.com/facebook-fact-che...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "      <td>480</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jill Terreri</td>\n",
       "      <td>A discrepancy in the number of ballots and vot...</td>\n",
       "      <td>New York Citizens Audit</td>\n",
       "      <td>October 29, 2023</td>\n",
       "      <td>false</td>\n",
       "      <td>New York Citizens Audit is comparing certified...</td>\n",
       "      <td>The claim is startling: New York’s election re...</td>\n",
       "      <td>interview,interview,interview,new_york_citizen...</td>\n",
       "      <td>elections,new_york,new_york_citizens_audit</td>\n",
       "      <td>['https://www.politifact.com/elections/', 'htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                           headline  \\\n",
       "0   Ciara O'Rourke  “The airport in Salzburg, Austria, has a count...   \n",
       "1   Ciara O'Rourke  Video shows Palestinians pretending to be corp...   \n",
       "2  Loreben Tuquero  The life span of a wind tower generator lasts ...   \n",
       "3   Ciara O'Rourke  Matthew Perry died because of a COVID-19 vaccine.   \n",
       "4     Jill Terreri  A discrepancy in the number of ballots and vot...   \n",
       "\n",
       "                    source              date target  \\\n",
       "0          Instagram posts  October 30, 2023  false   \n",
       "1              Viral image  October 30, 2023  false   \n",
       "2           Facebook posts  October 30, 2023  false   \n",
       "3          Instagram posts  October 30, 2023  false   \n",
       "4  New York Citizens Audit  October 29, 2023  false   \n",
       "\n",
       "                                           highlight  \\\n",
       "0  This rumor stems from an ad. No such counter e...   \n",
       "1  This video is 10 years old and shows student p...   \n",
       "2  A study by energy industry experts showed that...   \n",
       "3  Actor Matthew Perry died Oct. 28, but his caus...   \n",
       "4  New York Citizens Audit is comparing certified...   \n",
       "\n",
       "                                             article  \\\n",
       "0  A social media post poised to encourage people...   \n",
       "1  The Gaza Health Ministry has said the Palestin...   \n",
       "2  Let’s clear the air. Do wind turbine component...   \n",
       "3  Actor Matthew Perry died Oct. 28, setting off ...   \n",
       "4  The claim is startling: New York’s election re...   \n",
       "\n",
       "                                          references  \\\n",
       "0    instagram_post,the_local,washington_post,x_post   \n",
       "1              instagram_post,instagram_post,youtube   \n",
       "2  none,x_post,facebook_post,interview,interview,...   \n",
       "3  instagram_post,instagram_post,instagram_post,i...   \n",
       "4  interview,interview,interview,new_york_citizen...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  transportation,facebook_fact_checks,instagram_...   \n",
       "1            israel,facebook_fact_checks,viral_image   \n",
       "2  climate_change,energy,facebook_fact_checks,fac...   \n",
       "3   facebook_fact_checks,coronavirus,instagram_posts   \n",
       "4         elections,new_york,new_york_citizens_audit   \n",
       "\n",
       "                                       category_urls  src_true  \\\n",
       "0  ['https://www.politifact.com/transportation/',...         5   \n",
       "1  ['https://www.politifact.com/israel/', 'https:...         4   \n",
       "2  ['https://www.politifact.com/climate-change/',...        24   \n",
       "3  ['https://www.politifact.com/facebook-fact-che...         5   \n",
       "4  ['https://www.politifact.com/elections/', 'htt...         0   \n",
       "\n",
       "   src_mostly_true  src_half_true  src_mostly_false  src_false  \\\n",
       "0                3             16                54        480   \n",
       "1               13             35                53        764   \n",
       "2               50            108               247       1532   \n",
       "3                3             16                54        480   \n",
       "4                0              0                 0          1   \n",
       "\n",
       "   src_pants_on_fire  \n",
       "0                157  \n",
       "1                340  \n",
       "2                595  \n",
       "3                157  \n",
       "4                  0  "
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/politifact_plus.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
